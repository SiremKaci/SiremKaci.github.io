{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faeef99-691f-4d0d-a3db-8710b15855fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé : cpu\n",
      "Modèle : mobilenet_v3_small — Paramètres entraînables : 1,519,906\n",
      "\n",
      "Test rapide du train_loader...\n",
      "Batch 1 chargé (torch.Size([12, 3, 224, 224]))\n",
      "Batch 2 chargé (torch.Size([12, 3, 224, 224]))\n",
      "Batch 3 chargé (torch.Size([12, 3, 224, 224]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [09:13<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 0.5427 | Train Acc: 71.42% | Val Loss: 0.3791 | Val Acc: 82.86%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:44<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.4406 | Train Acc: 78.55% | Val Loss: 0.3576 | Val Acc: 86.36%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:29<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.4108 | Train Acc: 81.38% | Val Loss: 0.2939 | Val Acc: 88.83%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:15<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.3825 | Train Acc: 82.23% | Val Loss: 0.2623 | Val Acc: 89.87%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:21<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.3698 | Train Acc: 83.56% | Val Loss: 0.2916 | Val Acc: 87.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:38<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.3552 | Train Acc: 84.25% | Val Loss: 0.2777 | Val Acc: 89.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:28<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.3364 | Train Acc: 85.24% | Val Loss: 0.2488 | Val Acc: 90.00%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:51<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.3304 | Train Acc: 85.55% | Val Loss: 0.2451 | Val Acc: 90.78%\n",
      "→ Nouveau meilleur modèle sauvegardé : best_mobilenet_v3_small_glaucoma.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 [Train]: 100%|████████████████████████████████████████████████████████████| 694/694 [07:28<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.3175 | Train Acc: 85.57% | Val Loss: 0.2311 | Val Acc: 90.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 [Train]: 100%|███████████████████████████████████████████████████████████| 694/694 [07:24<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.3117 | Train Acc: 86.37% | Val Loss: 0.2672 | Val Acc: 88.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 [Train]: 100%|███████████████████████████████████████████████████████████| 694/694 [07:49<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.3138 | Train Acc: 86.30% | Val Loss: 0.2349 | Val Acc: 90.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 [Train]: 100%|███████████████████████████████████████████████████████████| 694/694 [07:38<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.2944 | Train Acc: 87.12% | Val Loss: 0.2637 | Val Acc: 89.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 [Train]:  19%|███████████▏                                               | 132/694 [01:24<06:26,  1.45it/s]"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Diagnostic du glaucome - Classification fundus (RIM-ONE + AIROGS)\n",
    "# =============================================================================\n",
    "# Pré-requis :\n",
    "#   - Python 3.8+\n",
    "#   - torch, torchvision, albumentations, tqdm, numpy\n",
    "#   - Dossier fusionné : C:\\Users\\MH-CONFIG\\Desktop\\glaucoma_fused\n",
    "#     avec sous-dossiers train/val/test chacun contenant 0/ et 1/\n",
    "#\n",
    "# Astuces performance Windows / CPU :\n",
    "#   - num_workers=0\n",
    "#   - batch_size 8-16\n",
    "#   - MobileNetV3-Small plus rapide qu'EfficientNet-B0\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Wrapper pour Albumentations\n",
    "# -----------------------------------------------------------------------------\n",
    "class AlbumentationsTransform:\n",
    "    \"\"\"Wrapper pour appliquer Albumentations à ImageFolder\"\"\"\n",
    "    def __init__(self, aug):\n",
    "        self.aug = aug\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)  # PIL -> numpy\n",
    "        augmented = self.aug(image=image)\n",
    "        return augmented[\"image\"]  # déjà un tensor grâce à ToTensorV2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Transformations\n",
    "# -----------------------------------------------------------------------------\n",
    "train_transform = AlbumentationsTransform(\n",
    "    A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=30, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "val_transform = AlbumentationsTransform(\n",
    "    A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Datasets et DataLoaders\n",
    "# -----------------------------------------------------------------------------\n",
    "data_path = r\"C:\\Users\\MH-CONFIG\\Desktop\\glaucoma_fused\"\n",
    "\n",
    "train_ds = ImageFolder(os.path.join(data_path, \"train\"), transform=train_transform)\n",
    "val_ds   = ImageFolder(os.path.join(data_path, \"val\"), transform=val_transform)\n",
    "test_ds  = ImageFolder(os.path.join(data_path, \"test\"), transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Modèle corrigé (MobileNetV3-Small)\n",
    "# -----------------------------------------------------------------------------\n",
    "class GlaucomaModel(nn.Module):\n",
    "    \"\"\"Classification binaire glaucome / sain\"\"\"\n",
    "    def __init__(self, model_name=\"mobilenet_v3_small\", num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"efficientnet_b0\":\n",
    "            self.base = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "            in_features = self.base.classifier[1].in_features\n",
    "            self.base.classifier = nn.Sequential(\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )\n",
    "\n",
    "        elif model_name == \"mobilenet_v3_small\":\n",
    "            self.base = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "            in_features = self.base.classifier[0].in_features  # <-- correction clé\n",
    "            self.base.classifier = nn.Sequential(\n",
    "                nn.Linear(in_features, 1024),\n",
    "                nn.Hardswish(),\n",
    "                nn.Dropout(p=0.5),\n",
    "                nn.Linear(1024, num_classes)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Modèle non supporté. Choisir 'efficientnet_b0' ou 'mobilenet_v3_small'\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base(x)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. Fonction principale (protection Windows)\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device utilisé : {device}\")\n",
    "\n",
    "    MODEL_NAME = \"mobilenet_v3_small\"\n",
    "    model = GlaucomaModel(model_name=MODEL_NAME).to(device)\n",
    "\n",
    "    # Paramètres entraînables\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Modèle : {MODEL_NAME} — Paramètres entraînables : {trainable_params:,}\")\n",
    "\n",
    "    # Loss, Optimizer, Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    # Debug DataLoader\n",
    "    print(\"\\nTest rapide du train_loader...\")\n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        print(f\"Batch {i+1} chargé ({imgs.shape})\")\n",
    "        if i >= 2: break\n",
    "\n",
    "    # Boucle d'entraînement\n",
    "    epochs = 10\n",
    "    best_val_acc = 0.0\n",
    "    save_path = f\"best_{MODEL_NAME}_glaucoma.pth\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss /= train_total\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= total\n",
    "        val_acc = 100. * correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Scheduler\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        # Sauvegarde si meilleur modèle\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"→ Nouveau meilleur modèle sauvegardé : {save_path}\")\n",
    "\n",
    "    print(\"\\nEntraînement terminé ! Meilleure Val Acc :\", best_val_acc)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Lancement sécurisé\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788521e-9a71-414f-a971-0dfcb5abb902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Projet]",
   "language": "python",
   "name": "conda-env-Projet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
